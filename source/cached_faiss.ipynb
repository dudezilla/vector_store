{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0964c303-a893-4f2e-be42-95bc0023450e",
   "metadata": {},
   "source": [
    " # Cache Backed FAISS.\n",
    "\n",
    " https://python.langchain.com/docs/how_to/caching_embeddings/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad70ca8c-4724-43fa-8b27-33095b4e8d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\spete\\Documents\\analtyics\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\spete\\AppData\\Local\\Temp\\ipykernel_20316\\3736482123.py:30: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  underlying_embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "C:\\Users\\spete\\Documents\\analtyics\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\spete\\Documents\\analtyics\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.tools import tool\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "#vector retriever tools\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain_community.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "#recursive why does that sound better?\n",
    "#from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "#from langgraph.checkpoint.memory import MemorySaver\n",
    "#from langgraph.prebuilt import create_react_agent\n",
    "from typing import List\n",
    "#from langchain_core.tools import tool\n",
    "from langchain_ollama import ChatOllama\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "underlying_embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "\n",
    "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings, store, namespace=\"all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a4652a8-418a-49c5-8793-c546295b3b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"input\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62005b24-0783-4ec1-a926-747adb7c3ba6",
   "metadata": {},
   "source": [
    "### Note the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a08e1ad-4988-46ac-a7e4-ca0931999f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all-MiniLM-L6-v21e5c5f16-2189-5d11-8943-a605b5b02e01',\n",
       " 'all-MiniLM-L6-v2319c63c0-1f35-51dc-9a04-e1fc4d7b1243',\n",
       " 'all-MiniLM-L6-v2329ee360-1b33-5515-9b76-2403727f8cd8',\n",
       " 'all-MiniLM-L6-v249ca3786-dc64-5098-bac6-a4cee17c85d5',\n",
       " 'all-MiniLM-L6-v26c96f969-60ec-50d7-ab28-276115267a97',\n",
       " 'all-MiniLM-L6-v28288888f-b8a7-5dac-8d9d-11c84fd302a9',\n",
       " 'all-MiniLM-L6-v2a625e1dc-4c12-54cf-82da-d4c8ba83d14e',\n",
       " 'all-MiniLM-L6-v2a7bc4680-996e-58fc-a9a0-e873c0702370',\n",
       " 'all-MiniLM-L6-v2af30bf4c-82fb-544a-86b0-fdee8485a842',\n",
       " 'all-MiniLM-L6-v2cf674ad3-5ef8-5f4c-a89a-97a284b71379',\n",
       " 'all-MiniLM-L6-v2dee9e127-6122-5300-b1a6-0fee083f2982',\n",
       " 'all-MiniLM-L6-v2eeb1f7b2-241a-55ff-828c-2d4b2dd4c26c',\n",
       " '.ipynb_checkpoints\\\\all-MiniLM-L6-v2eeb1f7b2-241a-55ff-828c-2d4b2dd4c26c-checkpoint']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(store.yield_keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13ebc8bb-9838-42f2-be72-76fce9a645d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading ./input/story.txt",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\analtyics\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py:42\u001b[0m, in \u001b[0;36mTextLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     43\u001b[0m         text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './input/story.txt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m raw_documents \u001b[38;5;241m=\u001b[39m \u001b[43mTextLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./input/story.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m CharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      3\u001b[0m documents \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(raw_documents)\n",
      "File \u001b[1;32m~\\Documents\\analtyics\\Lib\\site-packages\\langchain_core\\document_loaders\\base.py:30\u001b[0m, in \u001b[0;36mBaseLoader.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[0;32m     29\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\analtyics\\Lib\\site-packages\\langchain_community\\document_loaders\\text.py:58\u001b[0m, in \u001b[0;36mTextLoader.lazy_load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     60\u001b[0m metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path)}\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m Document(page_content\u001b[38;5;241m=\u001b[39mtext, metadata\u001b[38;5;241m=\u001b[39mmetadata)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error loading ./input/story.txt"
     ]
    }
   ],
   "source": [
    "raw_documents = TextLoader(\"./input/story.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc2496-f8c2-40ee-a8ba-d60b15dcf33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "db = FAISS.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b9768-c914-4b1c-9070-3d6c42273362",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "db2 = FAISS.from_documents(documents, cached_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238cb46e-1b75-4f13-aad9-4c2d80feb04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(store.yield_keys())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5382d-7d44-440a-8055-357923780d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a251426-ceb0-4f38-b292-6c0be722803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = retriever.invoke(\"Gwen Stills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8c4e78-fd7f-4e13-a37e-0d001606af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61b3be-e9ae-42fd-8b71-e9c9b7397e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in result:\n",
    "    print(f\"{el}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea152cfd-f54e-45a1-80d1-1fd477e223ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def query_documents(question):\n",
    "    \"\"\"\n",
    "    Uses RAG to query documents for information to answer a question\n",
    "    that requires specific context that could be found in documents\n",
    "\n",
    "    Example call:\n",
    "\n",
    "    query_documents(\"Who is Gwen Stills?\")\n",
    "    Args:\n",
    "        question (str): The question the user asked that might be answerable from the searchable documents\n",
    "    Returns:\n",
    "        str: The list of texts (and their sources) that matched with the question the closest using RAG\n",
    "    \"\"\"\n",
    "    similar_docs = db.similarity_search(question, k=3)\n",
    "    docs_formatted = list(map(lambda doc: f\"Source: {doc.metadata.get('source', 'NA')}\\nContent: {doc.page_content}\", similar_docs))\n",
    "\n",
    "    return str(docs_formatted)\n",
    "\n",
    "available_functions = {\n",
    "    \"query_documents\": query_documents\n",
    "}\n",
    "\n",
    "def get_model():\n",
    "    llm = ChatOllama( model=\"llama3.1\", temperature=0,)\n",
    "    return llm\n",
    "\n",
    "llm = get_model()\n",
    "llm_with_tools = llm.bind_tools([query_documents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31136e55-36f8-4e5b-88aa-0fe1ad9ba1fc",
   "metadata": {},
   "source": [
    "Steps to invoke a function call using Chat Completions API:\n",
    "\n",
    "Step 1: Prompt the model with content that may result in model selecting a tool to use. The description of the tools such as a function names and signature is defined in the 'Tools' list and passed to the model in API call. If selected, the function name and parameters are included in the response.\n",
    "\n",
    "Step 2: Check programmatically if model wanted to call a function. If true, proceed to step 3.\n",
    "\n",
    "Step 3: Extract the function name and parameters from response, call the function with parameters. Append the result to messages.\n",
    "\n",
    "Step 4: Invoke the chat completions API with the message list to get the response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad881bc1-a85e-4d51-9fdd-3e3c9fd9c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #1: Prompt with content that may result in function call. In this case the model can identify the information requested by the user is potentially available in the database schema passed to the model in Tools description. \n",
    "messages = [{\n",
    "    \"role\":\"user\", \n",
    "    \"content\": \"Who is Gwen Stills?\"\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386ccb36-06d1-4314-ac82-1b26a9a76a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc556ddb-fd19-4e84-8cba-7611528b87c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_message.tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27007855-096d-408f-9140-062a711f99d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_calls = response_message.tool_calls\n",
    "\n",
    "for tool_call in tool_calls:\n",
    "    #print(tool_call.keys())\n",
    "    tool_call_id = tool_call['id']\n",
    "    tool_name = tool_call['name']\n",
    "    args = tool_call['args']['question']\n",
    "\n",
    "    if tool_name in available_functions:\n",
    "        results = available_functions[tool_name](args)\n",
    "\n",
    "        messages.append({\n",
    "            \"role\":\"tool\", \n",
    "            \"tool_call_id\":tool_call_id, \n",
    "            \"name\": tool_name, \n",
    "            \"content\":results\n",
    "        })\n",
    "        # # Step 4: Invoke the chat completions API with the function response appended to the messages list\n",
    "        # # Note that messages with role 'tool' must be a response to a preceding message with 'tool_calls'\n",
    "        # model_response_with_function_call = client.chat.completions.create(\n",
    "        #     model=\"gpt-4o\",\n",
    "        #     messages=messages,\n",
    "        # )  # get a new response from the model where it can see the function response\n",
    "        model_response_with_function_call = llm_with_tools.invoke(messages)\n",
    "\n",
    "        print(model_response_with_function_call)\n",
    "        #print(model_response_with_function_call.choices[0].message.content)\n",
    "    else: \n",
    "        print(f\"Error: function {tool_function_name} does not exist\")\n",
    "else: \n",
    "    # Model did not identify a function to call, result can be returned to the user \n",
    "    print(response_message.content) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41819b9a-8e08-40cc-8655-2abb87bf484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_response_with_function_call.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257d815-32ba-49d4-bd86-2b9e88b26cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Step 2: determine if the response from the model includes a tool call.   \n",
    "tool_calls = response_message.tool_calls\n",
    "if tool_calls:\n",
    "    # If true the model will return the name of the tool / function to call and the argument(s)  \n",
    "    tool_call_id = tool_calls[0]\n",
    "    tool_function_name = tool_calls[0].function.name\n",
    "    tool_query_string = json.loads(tool_calls[0].function.arguments)['query']\n",
    "\n",
    "    # Step 3: Call the function and retrieve results. Append the results to the messages list.      \n",
    "    if tool_function_name == 'query_documents':\n",
    "        results = query_documents(conn, tool_query_string)\n",
    "        \n",
    "        messages.append({\n",
    "            \"role\":\"tool\", \n",
    "            \"tool_call_id\":tool_call_id, \n",
    "            \"name\": tool_function_name, \n",
    "            \"content\":results\n",
    "        })\n",
    "        \n",
    "        # # Step 4: Invoke the chat completions API with the function response appended to the messages list\n",
    "        # # Note that messages with role 'tool' must be a response to a preceding message with 'tool_calls'\n",
    "        # model_response_with_function_call = client.chat.completions.create(\n",
    "        #     model=\"gpt-4o\",\n",
    "        #     messages=messages,\n",
    "        # )  # get a new response from the model where it can see the function response\n",
    "        model_response_with_function_call = llm_with_tools.invoke(messages)\n",
    "        \n",
    "        print(model_response_with_function_call.choices[0].message.content)\n",
    "    else: \n",
    "        print(f\"Error: function {tool_function_name} does not exist\")\n",
    "else: \n",
    "    # Model did not identify a function to call, result can be returned to the user \n",
    "    print(response_message.content) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
